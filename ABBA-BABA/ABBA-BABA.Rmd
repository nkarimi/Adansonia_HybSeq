---
title: "ABBA-BABA tests"
author: "Nisa Karimi & Cécile Ané"
output:
    html_document:
        code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, comment=NA)
library(knitr)
```

# custom functions to get per-gene counts

Several functions are defined in external file `calcD.R`, which were
inspired / modified from the `CalcD` function in the
[`evobiR` package](https://github.com/coleoguy/evobir)

- `calcPatternCounts` takes a single 4-taxon alignment and calculates 3 numbers of sites:
  total, ABBA sites, and BABA sites.
  By default, sites with any ambiguity are dropped before calculating these 3 numbers
  (option `ambig="D"`).
- `calcD` takes a list of ABBA counts and a list of BABA counts, assuming that
  in each list: 1 count corresponds to 1 gene. It calculates the D statistics for
  the concatenated data, that is: [sum(ABBA) - sum(BABA)] / [sum(ABBA) + sum(BABA)]
- `calcDsd` takes a list of ABBA counts and a list of BABA counts, like `calcDsd`.
  It calculates the standard deviation of the D statistics using bootstrap, re-sampling
  loci. This is assuming independent loci (but not independent sites within loci).
  Default is 500 bootstrap replicates.

```{r, eval=FALSE}
library(seqinr) # for read.alignment. version 3.4-5
source("calcD.R")
```

So we read the individual gene alignments,

```{r}
countfilenames = c("ABBA-BABA-counts-primary372genes.csv",
                   "ABBA-BABA-counts-haplotype6-344genes.csv")
```

```{r, eval=FALSE}
dataset = "haplotype" # "primary"
datadir = ifelse(dataset == "primary", "../372genes_20190128", "../HH6_alignments")
filepattern = ifelse(dataset == "primary", ".FNA.fasta", "_subset.fasta")
cfn = countfilenames[ifelse(dataset=="primary",1,2)]
brevi = c("Asu001", "Aga001", "Aga002")
longi = c("Ape001", "Ape009", "Ama006", "Ama018", "Aza037", "Aza135")
digi = c("Adi001", "Adi002", "Adi003")
rubr = c("Aru001", "Aru127")
outg = c("Age001","Smi165", "Pcr070", "Bce020")
loci = list.files(datadir, pattern=".fasta$", full.names=T)
nloci = length(loci) # 372 (primary data set) or 344 (haplotype data set #6)
nquartets1 = length(brevi)*length(longi)*length(digi)*length(outg)
nquartets2 = length(brevi)*length(longi)*length(rubr)*length(outg)
nquartets  = nquartets1 + nquartets2
# 216 and 144 sets of 4 taxa. total: 360
cat("number of quartets:", nquartets1, "and", nquartets2)
```

then count the number of ABBA sites and BABA sites in each individual gene alignment,
and save these counts in file `ABBA-BABA-counts.csv`.

```{r, eval=F}
# initialize empty data frame to contain the results
countdata = data.frame(testset=rep(NA,nquartets*nloci))
countdata$testset_OG=NA
countdata$quartet=NA
countdata$p1=NA; countdata$p2=NA; countdata$p3=NA; countdata$p4=NA;
countdata$nsites = NA; countdata$abba = NA; countdata$baba = NA;
countdata$pattern = "no data"
countdata$locus = NA;
i=0
# for each test set
for (di in c(digi,rubr)){
  tset = ifelse(di %in% digi, "BLDO", "BLRO")
  # for each quartet representing (((Brevi,Longi),Adig),outgroup)
  #                            or (((Brevi,Longi),Arub),outgroup)
  for (ou in outg){ for (lo in longi){ for (br in brevi){
    cat(c(br,lo,di,ou), file="quartet.txt", sep="\n")
    qset = paste(gsub("A","",gsub("0","",c(br,lo,di,ou))), collapse="")
    # for each locus
    for (gene in loci){
      i = i+1
      countdata$testset[i] = tset
      countdata$quartet[i] = qset
      countdata$locus[i] = sub(paste0(datadir,"/"),"",sub(filepattern,"",gene))
      countdata[i,paste0("p",1:4)] = c(br,lo,di,ou)
      system(paste("python reorder_fasta.py", gene, "quartet.txt > quartet.fasta"))
      res = calcPatternCounts("quartet.fasta", ambig="D")
      countdata[i,c("nsites","abba","baba")] = res
    } # end of gene
  } # end of 1 quartet
}}} # end of all quartets and all test sets
countdata$pattern[which(countdata$abba+countdata$baba>0)] = "same"
countdata$pattern[countdata$baba> countdata$abba] = "more BABA"
countdata$pattern[countdata$abba> countdata$baba] = "more ABBA"
countdata$testset_OG = with(countdata, paste0(substr(testset, 1,3),
                                              ifelse(startsWith(p4, "A"), "A", "O")))
head(countdata)
write.csv(countdata, cfn, quote=F, row.names=F)
```


```{r, message=F, warning=F}
library(dplyr)
countdata = full_join( mutate(read.csv(countfilenames[2]), data="HH6"),
                       mutate(read.csv(countfilenames[1]), data="primary"))
```

check that the data structure is as expected:

- 257,760 rows: (372 + 344) genes * 360 number of 4-taxon sets
  (was 372*270 = on primary data without Age001)
- for each test set / quartet combination:
  either 0 genes (quartet not in that set) or 372+344 = 716 genes
- for 2574 = 90 + 2484 gene/quartet combinations, 1 or more sequence was missing
- for 9960 gene/quartet combinations, there were 0 sites
  (there might have been sequences, but all sites were ambiguous and removed before
  ABBA and BABA patterns were counted).

```{r, eval=F, message=F}
nrow(countdata) / (372 + 344) # 360 quartets
with(countdata, unique(table(quartet, testset))) # 0 and 716
c(sum(is.na(countdata$nsites)), sum(is.na(countdata$abba)), sum(is.na(countdata$baba))) # 2574 3 times
countdata %>% group_by(data) %>% filter(is.na(nsites)) %>% nrow() # 2574 rows with NA counts
countdata %>% group_by(data, testset_OG) %>% filter(nsites==0) %>% nrow() # 9960 rows with 0 sites
countdata %>% group_by(data, testset_OG) %>% filter(nsites==0) %>% summarize(n=n())
with(countdata, table(table(locus, data))) # either 0 or 360 four-taxon sets (no shared genes)
```

main signal (but no assessment of significance at this point):
for B <-> D and L <-> R, in terms of

- number of genes with more sites giving one pattern than the other:

```{r}
with(countdata, table(testset_OG, pattern, data))
```

- and total number sites giving one pattern versus the other:

```{r}
countdata %>% group_by(testset_OG, data) %>% filter(!is.na(nsites)) %>%
  summarize(nsites_abba=sum(abba), nsites_baba=sum(baba))
```

# D-statistic and bootstrap of loci to assess significance

```{r, eval=F}
dat = countdata %>% group_by(testset, testset_OG, data, quartet) %>%
  filter(!is.na(nsites)) %>% filter(nsites>0) %>%
  summarize(p1=p1[1], p2=p2[1], p3=p3[1], p4=p4[1],
      nsites=sum(nsites), nsites_abba=sum(abba), nsites_baba=sum(baba), nloci=n(),
      nloci_abba=sum(pattern=="more ABBA"), nloci_baba=sum(pattern=="more BABA"),
      D=calcD(abba,baba), bootSD=calcDsd(abba, baba, Nbootstrap=100000))
dat$zscore = dat$D/dat$bootSD
write.csv(dat, "ABBA-BABA-Dstat.csv", quote=F, row.names=F)
```

Quartets with most evidence, for example `|z| > 2.9`
(value chosen to get a list not too long and not too short):

```{r, message=F}
library(ggplot2)
library(wesanderson)
theme_set(theme_light())
dat = read.csv("ABBA-BABA-Dstat.csv")
dat$data = relevel(dat$data, "primary")
dat %>% filter(abs(zscore)>2.9) %>% arrange(zscore) %>% select(-quartet, -testset)
```

Now looking at the z-score across all quartets:

```{r, message=F}
testset.labs = sub("O","o", sub("A","g", sub("R","r", sub("D","d", levels(dat$testset_OG)))))
names(testset.labs) = levels(dat$testset_OG) # "BLDA" "BLDO" "BLRA" "BLRO"
ggplot(dat, aes(x=zscore, stat(density))) + geom_histogram(bins=50) +
  geom_vline(xintercept=0) +
  xlab("ABBA-BABA test z-score") +
  facet_wrap(~testset_OG, nrow=2, ncol=2, dir="v", labeller=labeller(testset_OG=testset.labs))
ggsave("Figure5a.abba-baba.png", height=4, width=6)
```

```{r, fig.height=11, fig.width=10}
ggplot(dat, aes(x=p2, y=zscore, color=data, fill=data)) +
  geom_boxplot(alpha=0.2) + facet_grid(testset_OG~p1) +
  theme(panel.grid.minor=element_blank()) + geom_hline(yintercept=0)
```

```{r, fig.height=2.5, fig.width=5}
ggplot(dat %>% filter(testset_OG=="BLRA"), aes(x=p2, y=zscore, color=p1, shape=p1)) +
  geom_point(alpha=0.8) +
  labs(color="Brevitubae\nrepresentative", shape="Brevitubae\nrepresentative") +
  facet_grid(~data, labeller=labeller(.cols=label_both)) +
  xlab("Longitubae representative") + ylab("ABBA-BABA test z-score") +
  geom_hline(yintercept=0) +
  scale_colour_manual(values=wes_palette(n=3, name="GrandBudapest1")) +
  theme(panel.grid.minor=element_blank(), axis.text.x=element_text(angle=45, hjust=1))
# ggsave("ABBA-BABA-BLRgregorii.pdf", height=2.8, width=7)
ggsave("Figure5b.abba-baba_byrep.png", height=2.8, width=6)
```

```{r, fig.height=6, fig.width=12}
ggplot(dat, aes(x=p2, y=zscore, color=data, fill=data)) +
  geom_boxplot(alpha=0.2) + facet_grid(testset~p4) +
  theme(panel.grid.minor=element_blank()) + geom_hline(yintercept=0)
```

# distribution of p-values

Next: median p-value, and proportion of quartets
that provide a p-value below 0.10,
depending on whether P2 = Perrieri or not.
I chose the median, because it corresponds to the median z-score,
whereas the mean p-value does *not* correspond to the mean z-score.

```{r}
dat$Ape = "P2 = ma or za"
dat$Ape[startsWith(as.character(dat$p2),"Ape")] = "P2 = pe"
dat$Bce = "Out = Pcr or Smi"
dat$Bce[startsWith(as.character(dat$p4),"Bce")] = "Out = Bce"
dat$Bce[startsWith(as.character(dat$p4),"Age")] = "Out = Age"
dat %>% group_by(testset, Bce, Ape) %>%
  summarize( median_p=median(pvalue),
             prop_below_0.10=sum(pvalue<.10)/n(),
             prop_above_0.90=sum(pvalue>.90)/n())
```

```{r, message=F, fig.width=8, fig.height=8}
ggplot(dat, aes(x=pvalue)) + geom_histogram() + facet_grid(Bce*Ape~testset)
```

```{r}
sessionInfo()
```

about multiple testing: multiple-testing correction is not warranted here,
because we would expect all quartets from the same test set to give the
exact same result.
We are testing the same hypothesis multiple times, not different hypotheses.
If variation in p-values is sampling variation, then
the best p-value to report is the median p-value or mean p-value,
perhaps (for each test set individually).
